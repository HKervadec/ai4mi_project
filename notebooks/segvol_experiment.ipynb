{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "2024-10-07 13:14:27.237059: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from models.segvol.base import SegVolConfig\n",
    "from models.segvol.lora_model import SegVolLoRA\n",
    "from utils.dataset import VolumetricDataset\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "img_path = \"../data/segthor_train/train/Patient_05/Patient_05.nii.gz\"\n",
    "gt_path = \"../data/segthor_train/train/Patient_05/GT.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.networks.nets.vit ViT.__init__:pos_embed: Argument `pos_embed` has been deprecated since version 1.2. It will be removed in version 1.4. please use `proj_type` instead.\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "`clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n"
     ]
    }
   ],
   "source": [
    "config = SegVolConfig(test_mode=False)\n",
    "\n",
    "# NOTE: The default spatial size is 32x256x256 which is not that much to capture the whole volume\n",
    "\n",
    "model = SegVolLoRA(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = VolumetricDataset(\"../data/segthor_train/train\", 0.9, model.processor, num_classes=5, cache_size=2, train=False)\n",
    "\n",
    "# Must be batch size 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "organs_cls = [\"esophagus\", \"heart\", \"trachea\", \"aorta\"]\n",
    "\n",
    "loss = 0\n",
    "\n",
    "for i, obj in enumerate(train_loader):\n",
    "    print(i)\n",
    "    image = obj[\"image\"].to(device)\n",
    "    gt3D = obj[\"label\"].to(device)\n",
    "    \n",
    "    for j in range(len(organs_cls)):\n",
    "        cat = organs_cls[j]\n",
    "        labels_cls = gt3D[:, j]\n",
    "        loss = model.forward_train(image, train_organs=cat, train_labels=labels_cls, modality=\"CT\") \n",
    "    \n",
    "    # Good to have manual memory management here\n",
    "    del obj\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         249337 function calls (248173 primitive calls) in 34.648 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  208/128   10.786    0.052   10.796    0.084 {method 'to' of 'torch._C.TensorBase' objects}\n",
      "    40/24    9.307    0.233    9.310    0.388 {built-in method torch.stack}\n",
      "     9240    3.020    0.000    3.020    0.000 {method 'decompress' of 'zlib.Decompress' objects}\n",
      "        4    2.160    0.540    2.160    0.540 {built-in method scipy.sparse._sparsetools.csr_todense}\n",
      "        4    1.590    0.398    1.590    0.398 {method 'min' of 'torch._C.TensorBase' objects}\n",
      "       28    1.410    0.050    6.384    0.228 format.py:738(read_array)\n",
      "       16    1.269    0.079    1.269    0.079 {method 'max' of 'torch._C.TensorBase' objects}\n",
      "        4    0.891    0.223    0.891    0.223 {built-in method numpy.fromfile}\n",
      "       16    0.889    0.056    0.889    0.056 {method 'any' of 'torch._C.TensorBase' objects}\n",
      "     9288    0.668    0.000    0.668    0.000 {built-in method zlib.crc32}\n",
      "        4    0.543    0.136    3.404    0.851 base.py:429(__call__)\n",
      "       16    0.428    0.027    0.428    0.027 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.320    0.320   34.646   34.646 <string>:1(<module>)\n",
      "        8    0.267    0.033   11.256    1.407 array.py:768(__call__)\n",
      "        4    0.196    0.049   24.530    6.133 dataset.py:82(_load_item)\n",
      "        8    0.185    0.023    0.185    0.023 {built-in method torch._C._nn._upsample_nearest_exact3d}\n",
      "     3605    0.131    0.000    0.131    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      "     9240    0.113    0.000    3.987    0.000 zipfile.py:1012(_read1)\n",
      "        4    0.081    0.020    0.081    0.020 utils.py:204(is_positive)\n",
      "       24    0.048    0.002    0.048    0.002 {built-in method torch.any}\n",
      "        4    0.046    0.011   25.004    6.251 dataset.py:109(__getitem__)\n",
      "     9304    0.035    0.000    4.027    0.000 zipfile.py:930(read)\n",
      "        4    0.030    0.007    1.051    0.263 utils.py:996(generate_spatial_bounding_box)\n",
      "     9292    0.024    0.000    4.049    0.000 format.py:951(_read_bytes)\n",
      "     9208    0.023    0.000    0.023    0.000 {built-in method numpy.frombuffer}\n",
      "        4    0.023    0.006    1.074    0.268 deprecate_utils.py:317(_wrapper)\n",
      "     3573    0.017    0.000    0.155    0.000 zipfile.py:768(read)\n",
      "102960/102956    0.014    0.000    0.015    0.000 {built-in method builtins.len}\n",
      "     9240    0.011    0.000    0.679    0.000 zipfile.py:965(_update_crc)\n",
      "     6181    0.011    0.000    0.166    0.000 zipfile.py:1048(_read2)\n",
      "    12708    0.008    0.000    0.008    0.000 {built-in method builtins.min}\n",
      "    12805    0.006    0.000    0.006    0.000 {built-in method builtins.max}\n",
      "     3577    0.006    0.000    0.006    0.000 {method 'tell' of '_io.BufferedReader' objects}\n",
      "  488/432    0.003    0.000    0.004    0.000 meta_obj.py:87(flatten_meta_objs)\n",
      "8954/8714    0.003    0.000    0.005    0.000 {built-in method builtins.isinstance}\n",
      "        4    0.003    0.001    0.003    0.001 {built-in method posix.stat}\n",
      "     3597    0.002    0.000    0.002    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
      "      136    0.002    0.000    0.007    0.000 type_conversion.py:134(_convert_tensor)\n",
      "        5    0.002    0.000    0.002    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "      200    0.002    0.000    9.324    0.047 meta_tensor.py:277(__torch_function__)\n",
      "      200    0.002    0.000    9.311    0.047 _tensor.py:1396(__torch_function__)\n",
      "        5    0.002    0.000   34.323    6.865 dataloader.py:626(__next__)\n",
      "       32    0.002    0.000    0.010    0.000 inverse.py:140(track_transform_meta)\n",
      "     3573    0.001    0.000    0.001    0.000 zipfile.py:1560(<lambda>)\n",
      "  360/120    0.001    0.000    0.003    0.000 type_conversion.py:176(convert_to_numpy)\n",
      "      864    0.001    0.000    0.003    0.000 meta_obj.py:106(copy_items)\n",
      "       56    0.001    0.000    0.009    0.000 type_conversion.py:335(convert_to_dst_type)\n",
      "       12    0.001    0.000    0.001    0.000 {built-in method torch.where}\n",
      "       88    0.001    0.000    0.001    0.000 {built-in method torch.eye}\n",
      "        1    0.001    0.001   34.648   34.648 {built-in method builtins.exec}\n",
      "      128    0.001    0.000    0.001    0.000 {built-in method torch.as_tensor}\n",
      "       24    0.001    0.000    5.504    0.229 npyio.py:235(__getitem__)\n",
      "     3582    0.001    0.000    0.001    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        8    0.001    0.000   10.987    1.373 functional.py:268(resize)\n",
      "      104    0.001    0.000    0.009    0.000 meta_tensor.py:173(update_meta)\n",
      "       28    0.001    0.000    0.001    0.000 {built-in method builtins.compile}\n",
      "      136    0.001    0.000   10.804    0.079 type_conversion.py:105(convert_to_tensor)\n",
      "      864    0.001    0.000    0.001    0.000 misc.py:134(is_immutable)\n",
      "      216    0.001    0.000    0.009    0.000 meta_obj.py:117(copy_meta_from)\n",
      "      408    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\n",
      "        4    0.001    0.000    0.001    0.000 socket.py:626(send)\n",
      "      216    0.001    0.000    0.004    0.000 meta_obj.py:136(<dictcomp>)\n",
      "       96    0.001    0.000    0.001    0.000 {method 'as_subclass' of 'torch._C.TensorBase' objects}\n",
      "        5    0.001    0.000    0.001    0.000 profiler.py:610(__exit__)\n",
      "      200    0.001    0.000    0.001    0.000 meta_tensor.py:45(_not_requiring_metadata)\n",
      "  392/200    0.001    0.000    0.002    0.000 _tensor.py:1507(_convert)\n",
      "       40    0.001    0.000    0.004    0.000 meta_tensor.py:118(__init__)\n",
      "        8    0.001    0.000    0.001    0.000 {method 'unsqueeze' of 'torch._C.TensorBase' objects}\n",
      "       28    0.001    0.000    0.001    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      159    0.001    0.000    0.001    0.000 {built-in method _abc._abc_instancecheck}\n",
      "       24    0.001    0.000    0.003    0.000 utils.py:942(to_affine_nd)\n",
      "        8    0.001    0.000    0.026    0.003 array.py:890(crop_pad)\n",
      "        4    0.001    0.000    1.076    0.269 array.py:871(compute_bounding_box)\n",
      "        5    0.001    0.000    0.001    0.000 sampler.py:152(__iter__)\n",
      "       88    0.001    0.000    0.007    0.000 type_conversion.py:266(convert_data_type)\n",
      "       24    0.001    0.000    9.312    0.388 collate.py:155(collate_tensor_fn)\n",
      "       48    0.001    0.000    0.004    0.000 meta_tensor.py:479(peek_pending_shape)\n",
      "       48    0.001    0.000    0.004    0.000 zipfile.py:1513(open)\n",
      "        8    0.001    0.000    0.001    0.000 {built-in method io.open}\n",
      "       68    0.001    0.000    0.001    0.000 {method 'numpy' of 'torch._C.TensorBase' objects}\n",
      "        4    0.001    0.000    0.002    0.000 _compressed.py:27(__init__)\n",
      "       32    0.001    0.000    0.001    0.000 twodim_base.py:158(eye)\n",
      "        4    0.001    0.000    0.001    0.000 {method 'clip' of 'torch._C.TensorBase' objects}\n",
      "        8    0.000    0.000    0.011    0.001 functional.py:213(crop_func)\n",
      "   228/28    0.000    0.000    0.000    0.000 ast.py:84(_convert)\n",
      " 1081/977    0.000    0.000    0.001    0.000 {built-in method builtins.hasattr}\n",
      "        8    0.000    0.000    0.186    0.023 functional.py:3829(interpolate)\n",
      "       28    0.000    0.000    0.003    0.000 format.py:587(_read_array_header)\n",
      "       16    0.000    0.000    4.510    0.282 transform.py:46(_apply_transform)\n",
      "        4    0.000    0.000    5.510    1.378 _matrix_io.py:80(load_npz)\n",
      "      280    0.000    0.000    0.002    0.000 type_conversion.py:66(get_equivalent_dtype)\n",
      "       42    0.000    0.000    0.000    0.000 {built-in method torch.empty}\n",
      "        4    0.000    0.000    1.102    0.276 dictionary.py:789(__call__)\n",
      "        8    0.000    0.000    0.001    0.000 utils.py:1795(scale_affine)\n",
      "        4    0.000    0.000    4.511    1.128 compose.py:333(__call__)\n",
      "       48    0.000    0.000    0.001    0.000 zipfile.py:820(__init__)\n",
      "       28    0.000    0.000    0.000    0.000 {built-in method torch.from_numpy}\n",
      "       80    0.000    0.000    0.002    0.000 meta_tensor.py:344(get_default_affine)\n",
      "      244    0.000    0.000    0.001    0.000 {built-in method builtins.all}\n",
      "        8    0.000    0.000    0.003    0.000 array.py:363(compute_slices)\n",
      "      496    0.000    0.000    0.001    0.000 {built-in method builtins.issubclass}\n",
      "      208    0.000    0.000    0.002    0.000 meta_tensor.py:206(<genexpr>)\n",
      "       72    0.000    0.000    0.000    0.000 meta_obj.py:81(__init__)\n",
      "      224    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        8    0.000    0.000    0.897    0.112 npyio.py:282(load)\n",
      "       12    0.000    0.000    0.048    0.004 utils_pytorch_numpy_unification.py:273(any_np_pt)\n",
      "     36/4    0.000    0.000    9.312    2.328 collate.py:88(collate)\n",
      "      132    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "       16    0.000    0.000    0.001    0.000 module.py:63(look_up_option)\n",
      "       16    0.000    0.000    0.001    0.000 functional.py:144(apply_pending_transforms_in_order)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'squeeze' of 'torch._C.TensorBase' objects}\n",
      "        4    0.000    0.000   11.256    2.814 dictionary.py:830(__call__)\n",
      "      120    0.000    0.000    0.001    0.000 typing.py:1572(__subclasscheck__)\n",
      "      120    0.000    0.000    0.001    0.000 typing.py:1297(__instancecheck__)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:3076(_bind)\n",
      "      400    0.000    0.000    0.000    0.000 _tensor.py:1414(<genexpr>)\n",
      "       48    0.000    0.000    0.000    0.000 {built-in method zlib.decompressobj}\n",
      "        4    0.000    0.000    0.002    0.000 zipfile.py:1361(_RealGetContents)\n",
      "       48    0.000    0.000    0.000    0.000 _tensor.py:996(__len__)\n",
      "       32    0.000    0.000    0.000    0.000 inverse.py:91(get_transform_info)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method torch.maximum}\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:1509(compute_divisible_spatial_size)\n",
      "        8    0.000    0.000    0.002    0.000 iostream.py:655(write)\n",
      "       48    0.000    0.000    0.000    0.000 {method 'detach' of 'torch._C.TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 _sputils.py:149(get_index_dtype)\n",
      "       16    0.000    0.000    0.000    0.000 twodim_base.py:234(diag)\n",
      "        8    0.000    0.000    0.007    0.001 functional.py:151(pad_func)\n",
      "      104    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}\n",
      "       40    0.000    0.000    0.001    0.000 meta_tensor.py:462(affine)\n",
      "       40    0.000    0.000    0.001    0.000 type_conversion.py:56(dtype_torch_to_numpy)\n",
      "        4    0.000    0.000    0.000    0.000 _compressed.py:135(check_format)\n",
      "      272    0.000    0.000    0.001    0.000 type_conversion.py:210(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 _methods.py:90(_clip)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler.}\n",
      "       44    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
      "       28    0.000    0.000    0.002    0.000 ast.py:54(literal_eval)\n",
      "       40    0.000    0.000    0.001    0.000 __init__.py:272(_compile)\n",
      "        8    0.000    0.000    0.001    0.000 utils.py:957(create_translate)\n",
      "        8    0.000    0.000    0.014    0.002 array.py:414(__call__)\n",
      "       36    0.000    0.000    0.000    0.000 transform.py:456(key_iterator)\n",
      "        2    0.000    0.000    0.000    0.000 ipkernel.py:775(_clean_thread_parent_frames)\n",
      "      224    0.000    0.000    0.000    0.000 meta_obj.py:175(meta)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:441(__call__)\n",
      "       64    0.000    0.000    0.001    0.000 misc.py:122(issequenceiterable)\n",
      "      240    0.000    0.000    0.000    0.000 _tensor.py:1516(<genexpr>)\n",
      "       48    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "       20    0.000    0.000    0.000    0.000 functional.py:83(apply_pending_transforms)\n",
      "       40    0.000    0.000    0.000    0.000 meta_tensor.py:467(affine)\n",
      "       12    0.000    0.000    0.000    0.000 misc.py:237(fall_back_tuple)\n",
      "        4    0.000    0.000    4.511    1.128 compose.py:47(execute_compose)\n",
      "        4    0.000    0.000   15.767    3.942 base.py:347(zoom_transform)\n",
      "      108    0.000    0.000    0.002    0.000 {built-in method builtins.any}\n",
      "       48    0.000    0.000    0.000    0.000 zipfile.py:1064(close)\n",
      "        4    0.000    0.000    9.312    2.328 collate.py:129(<dictcomp>)\n",
      "        4    0.000    0.000    0.002    0.001 dictionary.py:453(__call__)\n",
      "      208    0.000    0.000    0.000    0.000 meta_obj.py:235(is_batch)\n",
      "        7    0.000    0.000    0.000    0.000 threading.py:1161(ident)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method torch.zeros_like}\n",
      "       40    0.000    0.000    0.001    0.000 meta_tensor.py:105(__new__)\n",
      "      159    0.000    0.000    0.001    0.000 <frozen abc>:117(__instancecheck__)\n",
      "       12    0.000    0.000    0.002    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "        4    0.000    0.000    0.000    0.000 iostream.py:138(_event_pipe)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'swapaxes' of 'torch._C.TensorBase' objects}\n",
      "        4    0.000    0.000    0.001    0.000 iostream.py:259(schedule)\n",
      "       16    0.000    0.000    0.000    0.000 module.py:105(<setcomp>)\n",
      "        8    0.000    0.000    0.007    0.001 array.py:134(__call__)\n",
      "        8    0.000    0.000    0.000    0.000 utils.py:952(_create_scale)\n",
      "        8    0.000    0.000    0.000    0.000 utils.py:986(_create_translate)\n",
      "        8    0.000    0.000    0.000    0.000 array.py:278(compute_pad_width)\n",
      "        4    0.000    0.000    0.000    0.000 numeric.py:1855(isscalar)\n",
      "       16    0.000    0.000    0.000    0.000 type_conversion.py:61(dtype_numpy_to_torch)\n",
      "      248    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "       40    0.000    0.000    0.001    0.000 __init__.py:173(search)\n",
      "      108    0.000    0.000    0.000    0.000 {built-in method _struct.unpack}\n",
      "        8    0.000    0.000    0.001    0.000 collate.py:177(collate_numpy_array_fn)\n",
      "      432    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}\n",
      "      152    0.000    0.000    0.000    0.000 meta_obj.py:210(pending_operations)\n",
      "        5    0.000    0.000    0.000    0.000 _ops.py:512(__call__)\n",
      "       16    0.000    0.000    0.000    0.000 misc.py:171(ensure_tuple_rep)\n",
      "      132    0.000    0.000    0.000    0.000 <frozen abc>:121(__subclasscheck__)\n",
      "       12    0.000    0.000    0.001    0.000 utils_pytorch_numpy_unification.py:140(where)\n",
      "        8    0.000    0.000    0.001    0.000 array.py:410(__call__)\n",
      "        8    0.000    0.000    0.000    0.000 contextlib.py:546(__exit__)\n",
      "       48    0.000    0.000    0.000    0.000 zipfile.py:728(_get_decompressor)\n",
      "       16    0.000    0.000    4.510    0.282 transform.py:101(apply_transform)\n",
      "       28    0.000    0.000    0.000    0.000 format.py:282(descr_to_dtype)\n",
      "       48    0.000    0.000    0.000    0.000 meta_obj.py:195(applied_operations)\n",
      "        4    0.000    0.000    0.001    0.000 fromnumeric.py:40(_wrapit)\n",
      "       40    0.000    0.000    0.000    0.000 {method 'flush' of 'zlib.Decompress' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch.randperm}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "       28    0.000    0.000    0.002    0.000 utils.py:1027(safe_eval)\n",
      "        4    0.000    0.000    0.000    0.000 _base.py:1303(_get_index_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 _sputils.py:296(check_shape)\n",
      "        4    0.000    0.000    0.002    0.000 zipfile.py:1245(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 enums.py:87(__str__)\n",
      "       24    0.000    0.000    0.001    0.000 meta_tensor.py:490(peek_pending_affine)\n",
      "       48    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\n",
      "       26    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C.TensorBase' objects}\n",
      "      268    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "       16    0.000    0.000    0.001    0.000 meta_tensor.py:504(peek_pending_rank)\n",
      "       28    0.000    0.000    0.001    0.000 format.py:223(read_magic)\n",
      "      205    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "      104    0.000    0.000    0.003    0.000 misc.py:113(first)\n",
      "       44    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "        8    0.000    0.000    0.001    0.000 utils.py:925(create_scale)\n",
      "        4    0.000    0.000    0.001    0.000 zipfile.py:285(_EndRecData)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:571(_code)\n",
      "       24    0.000    0.000    0.000    0.000 zipfile.py:372(__init__)\n",
      "        4    0.000    0.000    2.160    0.540 _compressed.py:1178(toarray)\n",
      "      104    0.000    0.000    0.000    0.000 meta_obj.py:240(is_batch)\n",
      "       48    0.000    0.000    0.000    0.000 misc.py:143(ensure_tuple)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "       56    0.000    0.000    0.000    0.000 enum.py:192(__get__)\n",
      "       20    0.000    0.000    0.000    0.000 functional.py:124(<listcomp>)\n",
      "        4    0.000    0.000    0.002    0.000 {built-in method builtins.print}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:447(_parse_sub)\n",
      "        8    0.000    0.000    0.002    0.000 functional.py:56(_maybe_new_metatensor)\n",
      "        4    0.000    0.000   34.317    8.579 fetch.py:46(fetch)\n",
      "       54    0.000    0.000    0.001    0.000 {built-in method builtins.next}\n",
      "        4    0.000    0.000    0.000    0.000 _compressed.py:1295(prune)\n",
      "       32    0.000    0.000    0.000    0.000 inverse.py:86(transform_info_keys)\n",
      "       72    0.000    0.000    0.000    0.000 cp437.py:14(decode)\n",
      "        8    0.000    0.000    0.001    0.000 inverse.py:103(push_transform)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:509(_compile_info)\n",
      "       48    0.000    0.000    0.000    0.000 {function ZipExtFile.close at 0x10e678c20}\n",
      "        1    0.000    0.000    0.000    0.000 ipkernel.py:790(<setcomp>)\n",
      "       12    0.000    0.000    0.000    0.000 contextlib.py:460(__init__)\n",
      "       84    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "      252    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        8    0.000    0.000    0.000    0.000 getlimits.py:685(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 npyio.py:212(close)\n",
      "        8    0.000    0.000    0.000    0.000 fromnumeric.py:537(swapaxes)\n",
      "      164    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "      210    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'cpu' of 'torch._C.TensorBase' objects}\n",
      "        8    0.000    0.000    0.000    0.000 fromnumeric.py:1565(diagonal)\n",
      "      200    0.000    0.000    0.000    0.000 meta_obj.py:46(get_track_meta)\n",
      "       64    0.000    0.000    0.000    0.000 enum.py:795(<genexpr>)\n",
      "       56    0.000    0.000    0.000    0.000 enum.py:1243(value)\n",
      "       48    0.000    0.000    0.000    0.000 zipfile.py:779(close)\n",
      "        8    0.000    0.000    0.004    0.001 <frozen _collections_abc>:771(get)\n",
      "        4    0.000    0.000    0.002    0.000 npyio.py:185(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:350(check_non_lazy_pending_ops)\n",
      "        8    0.000    0.000    0.000    0.000 iostream.py:550(_is_master_process)\n",
      "        8    0.000    0.000    0.000    0.000 array.py:412(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
      "        8    0.000    0.000    0.000    0.000 enum.py:1221(__format__)\n",
      "       72    0.000    0.000    0.000    0.000 {built-in method _codecs.charmap_decode}\n",
      "       28    0.000    0.000    0.000    0.000 py3k.py:49(isfileobj)\n",
      "        4    0.000    0.000    0.000    0.000 _tensor.py:1058(__array__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'clip' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.000    0.000 _base.py:113(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:565(__init__)\n",
      "       28    0.000    0.000    0.001    0.000 ast.py:33(parse)\n",
      "       32    0.000    0.000    0.000    0.000 meta_tensor.py:348(as_tensor)\n",
      "      184    0.000    0.000    0.000    0.000 meta_obj.py:148(get_default_applied_operations)\n",
      "        8    0.000    0.000    0.000    0.000 functional.py:226(<listcomp>)\n",
      "       16    0.000    0.000    0.000    0.000 enum.py:791(__iter__)\n",
      "        8    0.000    0.000    0.000    0.000 array.py:272(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "       48    0.000    0.000    0.000    0.000 zipfile.py:747(__init__)\n",
      "       52    0.000    0.000    0.000    0.000 zipfile.py:1992(_fpclose)\n",
      "        4    0.000    0.000    0.001    0.000 fromnumeric.py:2100(clip)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "       96    0.000    0.000    0.000    0.000 {method 'indices' of 'slice' objects}\n",
      "        4    0.000    0.000    0.002    0.000 npyio.py:91(zipfile_factory)\n",
      "        8    0.000    0.000    0.000    0.000 type_conversion.py:207(<listcomp>)\n",
      "       48    0.000    0.000    0.000    0.000 misc.py:278(<genexpr>)\n",
      "       48    0.000    0.000    0.000    0.000 zipfile.py:1472(getinfo)\n",
      "       12    0.000    0.000    0.000    0.000 <frozen _collections_abc>:315(__subclasshook__)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1494(enumerate)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C.TensorBase' objects}\n",
      "       18    0.000    0.000    0.000    0.000 {method 'tolist' of 'torch._C.TensorBase' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "       18    0.000    0.000    0.000    0.000 enum.py:1091(__new__)\n",
      "      104    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C.TensorBase' objects}\n",
      "        8    0.000    0.000    0.000    0.000 array.py:111(__init__)\n",
      "       32    0.000    0.000    0.000    0.000 functional.py:3941(<genexpr>)\n",
      "        5    0.000    0.000    0.001    0.000 sampler.py:274(__iter__)\n",
      "        8    0.000    0.000    0.000    0.000 array.py:289(<listcomp>)\n",
      "        8    0.000    0.000    0.000    0.000 utils.py:1811(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen posixpath>:71(join)\n",
      "       24    0.000    0.000    0.000    0.000 functional.py:3790(_is_integer)\n",
      "        5    0.000    0.000   34.318    6.864 dataloader.py:673(_next_data)\n",
      "        5    0.000    0.000    0.000    0.000 profiler.py:593(__init__)\n",
      "       24    0.000    0.000    0.000    0.000 zipfile.py:491(_decodeExtra)\n",
      "        8    0.000    0.000    0.000    0.000 contextlib.py:490(enter_context)\n",
      "       18    0.000    0.000    0.000    0.000 enum.py:685(__call__)\n",
      "        8    0.000    0.000    0.000    0.000 _methods.py:55(_any)\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:507(_parse)\n",
      "        2    0.000    0.000    0.000    0.000 _compiler.py:241(_optimize_charset)\n",
      "        4    0.000    0.000    0.000    0.000 _tensor.py:1068(__array_wrap__)\n",
      "       32    0.000    0.000    0.000    0.000 meta_obj.py:204(push_applied_operation)\n",
      "        8    0.000    0.000    0.000    0.000 functional.py:234(<listcomp>)\n",
      "       60    0.000    0.000    0.000    0.000 format.py:652(<genexpr>)\n",
      "       56    0.000    0.000    0.000    0.000 array.py:280(<genexpr>)\n",
      "       96    0.000    0.000    0.000    0.000 {built-in method numpy.ascontiguousarray}\n",
      "       24    0.000    0.000    0.000    0.000 collate.py:129(<listcomp>)\n",
      "       52    0.000    0.000    0.000    0.000 zipfile.py:693(_check_compression)\n",
      "        5    0.000    0.000    0.002    0.000 profiler.py:604(__enter__)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'diagonal' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:3207(bind)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "       56    0.000    0.000    0.000    0.000 array.py:282(<genexpr>)\n",
      "        8    0.000    0.000    0.000    0.000 misc.py:158(ensure_tuple_size)\n",
      "        4    0.000    0.000    0.000    0.000 _base.py:1290(_process_toarray_args)\n",
      "       28    0.000    0.000    0.000    0.000 format.py:196(_check_version)\n",
      "       36    0.000    0.000    0.000    0.000 misc.py:238(<lambda>)\n",
      "        4    0.000    0.000    9.312    2.328 collate.py:216(default_collate)\n",
      "       16    0.000    0.000    0.000    0.000 _base.py:294(nnz)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
      "       20    0.000    0.000    0.000    0.000 functional.py:123(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 _sputils.py:240(isshape)\n",
      "        4    0.000    0.000   25.004    6.251 fetch.py:51(<listcomp>)\n",
      "       16    0.000    0.000    0.000    0.000 meta_obj.py:217(has_pending_operations)\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "        8    0.000    0.000    0.000    0.000 iostream.py:505(parent_header)\n",
      "       12    0.000    0.000    0.000    0.000 _base.py:73(_shape_as_2d)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:162(__getitem__)\n",
      "        4    0.000    0.000    0.000    0.000 _data.py:21(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 contextlib.py:522(_push_cm_exit)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:738(compile)\n",
      "        8    0.000    0.000    0.001    0.000 iostream.py:577(_schedule_flush)\n",
      "       72    0.000    0.000    0.000    0.000 meta_obj.py:139(get_default_meta)\n",
      "       28    0.000    0.000    0.000    0.000 {built-in method _struct.calcsize}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 sampler.py:145(num_samples)\n",
      "        8    0.000    0.000    0.000    0.000 collate.py:183(<listcomp>)\n",
      "       68    0.000    0.000    0.000    0.000 {built-in method _operator.index}\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:405(parent)\n",
      "        4    0.000    0.000    0.000    0.000 zipfile.py:242(_EndRecData64)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:970(parse)\n",
      "       32    0.000    0.000    0.000    0.000 array.py:835(<genexpr>)\n",
      "       56    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:659(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 zipfile.py:1876(close)\n",
      "        4    0.000    0.000    0.000    0.000 _base.py:1335(issparse)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:90(RLock)\n",
      "        5    0.000    0.000    0.002    0.000 _ops.py:750(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 getlimits.py:709(max)\n",
      "       48    0.000    0.000    0.000    0.000 {method 'seekable' of '_io.BufferedReader' objects}\n",
      "       40    0.000    0.000    0.000    0.000 inspect.py:2751(kind)\n",
      "       96    0.000    0.000    0.000    0.000 {method 'read' of '_io.BytesIO' objects}\n",
      "        2    0.000    0.000    0.000    0.000 _compiler.py:386(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:463(pop_all)\n",
      "       32    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        2    0.000    0.000    0.000    0.000 _compiler.py:384(_mk_bitmap)\n",
      "       24    0.000    0.000    0.000    0.000 worker.py:89(get_worker_info)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method sys.exc_info}\n",
      "        4    0.000    0.000    0.000    0.000 npyio.py:209(__exit__)\n",
      "       28    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\n",
      "       40    0.000    0.000    0.000    0.000 inspect.py:2739(name)\n",
      "        4    0.000    0.000    0.003    0.001 <frozen genericpath>:16(exists)\n",
      "       16    0.000    0.000    0.000    0.000 _compressed.py:114(_getnnz)\n",
      "        8    0.000    0.000    0.000    0.000 transform.py:297(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 typing.py:349(inner)\n",
      "       48    0.000    0.000    0.000    0.000 zipfile.py:755(tell)\n",
      "        8    0.000    0.000    0.000    0.000 contextlib.py:527(_push_exit_callback)\n",
      "        3    0.000    0.000    0.000    0.000 dataset.py:79(__len__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        4    0.000    0.000    0.000    0.000 getlimits.py:696(min)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:1515(__and__)\n",
      "        8    0.000    0.000    0.000    0.000 _util.py:225(_prune_array)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
      "       16    0.000    0.000    0.000    0.000 meta_obj.py:188(applied_operations)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'startswith' of 'bytes' objects}\n",
      "       32    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:2831(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:37(_compile)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:172(getwidth)\n",
      "        2    0.000    0.000    0.000    0.000 _compiler.py:214(_compile_charset)\n",
      "        4    0.000    0.000    0.000    0.000 npyio.py:72(__init__)\n",
      "       24    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
      "        7    0.000    0.000    0.000    0.000 _parser.py:231(__next)\n",
      "        4    0.000    0.000    0.000    0.000 dictionary.py:785(requires_current_data)\n",
      "        5    0.000    0.000    0.001    0.000 dataloader.py:620(_next_index)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C.TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 zipfile.py:1441(namelist)\n",
      "        8    0.000    0.000    0.000    0.000 contextlib.py:450(_create_exit_wrapper)\n",
      "       13    0.000    0.000    0.000    0.000 _jit_internal.py:1120(is_scripting)\n",
      "        8    0.000    0.000    0.000    0.000 {method '__format__' of 'str' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method '__enter__' of '_io._IOBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:222(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 zipfile.py:1443(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "        4    0.000    0.000    0.000    0.000 fromnumeric.py:2096(_clip_dispatcher)\n",
      "       16    0.000    0.000    0.000    0.000 functional.py:38(_log_pending_info)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}\n",
      "       16    0.000    0.000    0.000    0.000 twodim_base.py:230(_diag_dispatcher)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'get' of '_contextvars.ContextVar' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method builtins.chr}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:74(create_fetcher)\n",
      "        6    0.000    0.000    0.000    0.000 _parser.py:252(get)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:382(_get_iterator)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen posixpath>:41(_get_sep)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:434(_get_literal_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:444(_uniq)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.000    0.000 transform.py:303(lazy)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedReader' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:93(_get_distributed_settings)\n",
      "       16    0.000    0.000    0.000    0.000 _csr.py:160(_swap)\n",
      "        8    0.000    0.000    0.000    0.000 _sputils.py:336(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 zipfile.py:1872(__del__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:9(is_available)\n",
      "        8    0.000    0.000    0.000    0.000 fromnumeric.py:533(_swapaxes_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:426(__iter__)\n",
      "        4    0.000    0.000    0.000    0.000 npyio.py:225(__del__)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:465(_get_charset_prefix)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:3032(parameters)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:109(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:73(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 _parser.py:247(match)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:948(is_initialized)\n",
      "        2    0.000    0.000    0.000    0.000 _parser.py:284(tell)\n",
      "        8    0.000    0.000    0.000    0.000 fromnumeric.py:1561(_diagonal_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}\n",
      "        4    0.000    0.000    0.000    0.000 _data.py:24(dtype)\n",
      "        2    0.000    0.000    0.000    0.000 _parser.py:79(groups)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
      "        8    0.000    0.000    0.000    0.000 multiarray.py:503(can_cast)\n",
      "        2    0.000    0.000    0.000    0.000 _compiler.py:568(isstring)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:954(fix_flags)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:583(WORLD)\n",
      "        8    0.000    0.000    0.000    0.000 contextlib.py:543(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 fetch.py:8(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 _base.py:124(shape)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'pop' of 'collections.deque' objects}\n",
      "        2    0.000    0.000    0.000    0.000 _compiler.py:426(_get_iscased)\n",
      "        4    0.000    0.000    0.000    0.000 _csr.py:88(tocsr)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:441(_auto_collation)\n",
      "        4    0.000    0.000    0.000    0.000 npyio.py:206(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "        5    0.000    0.000    0.000    0.000 __init__.py:126(annotate)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:170(append)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 tz.py:74(utcoffset)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:445(_index_sampler)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:158(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:453(default_pg)"
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "for i, obj in enumerate(train_loader):\n",
    "    print(i)\n",
    "    image = obj[\"image\"].to(device)\n",
    "    gt3D = obj[\"label\"].to(device)\n",
    "\n",
    "    del obj, image, gt3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in train_loader:\n",
    "    image, gt3D = obj[\"image\"].to(device), obj[\"label\"].to(device)\n",
    "    for j in range(len(organs_cls)):\n",
    "        cat = organs_cls[j]\n",
    "        labels_cls = gt3D[:, j]\n",
    "        loss = model.forward_train(image, train_organs=cat, train_labels=labels_cls, modality=\"CT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
